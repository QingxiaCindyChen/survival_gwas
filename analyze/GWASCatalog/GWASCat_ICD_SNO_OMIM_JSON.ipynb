{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective - pull the ICD9 text from the GWAS catalog URLs, then use the latest phecode mapping\n",
    "#Inputs - gwas_catalog_v1.0.2-associations.tsv, phecode_icd9_rolled.csv\n",
    "#Outputs - GWASCatalog_ICD9_Mapped.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "import urllib, re, gc, requests\n",
    "from pathos.helpers import mp\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srhoades/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (23,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "GWASCat = pd.read_table('gwas_catalog_v1.0.2-associations.tsv')\n",
    "GWASCat = GWASCat[~(GWASCat.MAPPED_TRAIT_URI.astype(str)=='nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workaround to str.split() - @https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows/40449726\n",
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICDDictMapJSON(URLList): #JSON read more reliable than scrape?\n",
    "    DictOut = dict()\n",
    "    for url in URLList:\n",
    "        Suburl = re.split('\\,', url)\n",
    "        Suburl = [re.sub(' ', '', x) for x in Suburl]\n",
    "        minilist = []\n",
    "        for suburl in Suburl:\n",
    "            #Multiple URLs may exist.. split into list and find all ICDs within\n",
    "            urlopen = 'https://www.ebi.ac.uk/ols/api/ontologies/efo/terms?iri={0}'.format(suburl)\n",
    "            urlget = requests.get(urlopen).json()\n",
    "            try:\n",
    "                #Ridiculous structure\n",
    "                icds = urlget['_embedded']['terms'][0]['annotation']['ICD9_definition_citation']\n",
    "                icds = [re.sub('ICD9\\:', '', x) for x in icds]\n",
    "                minilist.append(icds)\n",
    "            except:\n",
    "                continue\n",
    "        Add = list(set(chain.from_iterable(minilist)))\n",
    "        DictOut[url] = list(set(Add))\n",
    "    \n",
    "    return(DictOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMIMDictMapJSON(URLList):\n",
    "    DictOut = dict()\n",
    "    for url in URLList:\n",
    "        #Multiple URLs may exist.. split into list and find all ICDs within\n",
    "        Suburl = re.split('\\,', url)\n",
    "        Suburl = [re.sub(' ', '', x) for x in Suburl]\n",
    "        minilist = []\n",
    "        for suburl in Suburl:\n",
    "            #Multiple URLs may exist.. split into list and find all ICDs within\n",
    "            urlopen = 'https://www.ebi.ac.uk/ols/api/ontologies/efo/terms?iri={0}'.format(suburl)\n",
    "            urlget = requests.get(urlopen).json()\n",
    "            try:\n",
    "                #Ridiculous structure\n",
    "                omims = urlget['_embedded']['terms'][0]['annotation']['OMIM_definition_citation']\n",
    "                omims = [re.sub('OMIM\\:', '', x) for x in omims]\n",
    "                minilist.append(omims)\n",
    "            except:\n",
    "                continue   \n",
    "        Add = list(set(chain.from_iterable(minilist)))\n",
    "        DictOut[url] = list(set(Add))\n",
    "        \n",
    "    return(DictOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNODictMapJSON(URLList):\n",
    "    DictOut = dict()\n",
    "    for url in URLList:\n",
    "        #Multiple URLs may exist.. split into list and find all ICDs within\n",
    "        Suburl = re.split('\\,', url)\n",
    "        Suburl = [re.sub(' ', '', x) for x in Suburl]\n",
    "        minilist = []\n",
    "        for suburl in Suburl:\n",
    "            #Multiple URLs may exist.. split into list and find all ICDs within\n",
    "            urlopen = 'https://www.ebi.ac.uk/ols/api/ontologies/efo/terms?iri={0}'.format(suburl)\n",
    "            urlget = requests.get(urlopen).json()\n",
    "            try:\n",
    "                #Ridiculous structure\n",
    "                snos = urlget['_embedded']['terms'][0]['annotation']['SNOMEDCT_definition_citation']\n",
    "                snos = [re.sub('SNOMEDCT\\:', '', x) for x in snos]\n",
    "                minilist.append(snos)\n",
    "            except:\n",
    "                continue\n",
    "        Add = list(set(chain.from_iterable(minilist)))\n",
    "        DictOut[url] = list(set(Add))\n",
    "        \n",
    "    return(DictOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1119"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CoreNum = 30\n",
    "\n",
    "URLs = list(set(GWASCat.MAPPED_TRAIT_URI))\n",
    "URLs = [x for x in URLs if str(x)!='nan']\n",
    "\n",
    "ICDDictList = []\n",
    "URLSplit = list(np.array_split(URLs, CoreNum))\n",
    "\n",
    "pooler=mp.Pool(CoreNum)\n",
    "\n",
    "for result in pooler.imap(ICDDictMapJSON, URLSplit):\n",
    "    ICDDictList.append(result)\n",
    "    \n",
    "pooler.close()\n",
    "pooler.join()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoreNum = 30\n",
    "\n",
    "URLs = list(set(GWASCat.MAPPED_TRAIT_URI))\n",
    "URLs = [x for x in URLs if str(x)!='nan']\n",
    "\n",
    "OMIMDictList = []\n",
    "URLSplit = list(np.array_split(URLs, CoreNum))\n",
    "\n",
    "pooler=mp.Pool(CoreNum)\n",
    "\n",
    "for result in pooler.imap(OMIMDictMapJSON, URLSplit):\n",
    "    OMIMDictList.append(result)\n",
    "    \n",
    "pooler.close()\n",
    "pooler.join()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoreNum = 30\n",
    "\n",
    "URLs = list(set(GWASCat.MAPPED_TRAIT_URI))\n",
    "URLs = [x for x in URLs if str(x)!='nan']\n",
    "\n",
    "SNODictList = []\n",
    "URLSplit = list(np.array_split(URLs, CoreNum))\n",
    "\n",
    "pooler=mp.Pool(CoreNum)\n",
    "\n",
    "for result in pooler.imap(SNODictMapJSON, URLSplit):\n",
    "    SNODictList.append(result)\n",
    "    \n",
    "pooler.close()\n",
    "pooler.join()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Say you have list of dictionaries\n",
    "FinalICDDict = dict()\n",
    "for d in ICDDictList:\n",
    "    FinalICDDict.update(d)\n",
    "FinalOMIMDict = dict()\n",
    "for d in OMIMDictList:\n",
    "    FinalOMIMDict.update(d)\n",
    "FinalSNODict = dict()\n",
    "for d in SNODictList:\n",
    "    FinalSNODict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GWASCat['ICD'] = [FinalICDDict[x] for x in GWASCat['MAPPED_TRAIT_URI']]\n",
    "GWASCat['OMIM'] = [FinalOMIMDict[x] for x in GWASCat['MAPPED_TRAIT_URI']]\n",
    "GWASCat['SNOMEDCT'] = [FinalSNODict[x] for x in GWASCat['MAPPED_TRAIT_URI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GWASCat = explode(GWASCat, ['ICD'], fill_value='')\n",
    "GWASCat.reset_index(inplace=True)\n",
    "del GWASCat['index']\n",
    "GWASCat = explode(GWASCat, ['OMIM'], fill_value='')\n",
    "GWASCat.reset_index(inplace=True)\n",
    "del GWASCat['index']\n",
    "GWASCat = explode(GWASCat, ['SNOMEDCT'], fill_value='')\n",
    "GWASCat.reset_index(inplace=True)\n",
    "del GWASCat['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GWASCat.to_csv('GWASCatalog_ICD9_OMIM_SNOMEDCT_Map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
